{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "phJWgHX0izsJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vijaykirandegala/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/var/folders/hq/f1b__lr163q9r1ljj554kc400000gn/T/ipykernel_4259/3388429253.py:25: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings(model=embedding_model_name)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain.tools import tool\n",
        "import requests\n",
        "from openai import OpenAI\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "import jsonschema_specifications\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.agents import Tool, initialize_agent, AgentType\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "client = OpenAI( api_key=os.environ.get('OPENAI_API_KEY') )\n",
        "\n",
        "# Initialize the OpenAI Embeddings model\n",
        "embedding_model_name = \"text-embedding-ada-002\"  # Recommended OpenAI text embedding model\n",
        "embeddings = OpenAIEmbeddings(model=embedding_model_name)\n",
        "\n",
        "\n",
        "# Open the JSON file\n",
        "with open('Clinical_Trials_Data.json') as f:\n",
        "    # Load the JSON data into a variable\n",
        "    all_trials = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SoDx5GZM2DnQ"
      },
      "outputs": [],
      "source": [
        "# Function to extract patient data\n",
        "def extract_patient_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    data = data['entry']\n",
        "\n",
        "    # Variables to hold extracted data\n",
        "    patient_data = {}\n",
        "    conditions = []\n",
        "    care_plans = []\n",
        "    encounters = []\n",
        "    diagnostic_reports = []\n",
        "    observations = []\n",
        "    procedures = []\n",
        "\n",
        "    for entry in data:\n",
        "        resource = entry['resource']\n",
        "        resource_type = resource['resourceType']\n",
        "\n",
        "        if resource_type == \"Patient\":\n",
        "            patient = resource\n",
        "            patient_data['name'] = patient['name'][0]['family'] if 'name' in patient else None\n",
        "            patient_data['gender'] = patient.get('gender', None)\n",
        "            patient_data['birthDate'] = patient.get('birthDate', None)\n",
        "\n",
        "            for ext in patient.get('extension', []):\n",
        "                if ext['url'] == 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-race':\n",
        "                    patient_data['race'] = ext['extension'][0]['valueCoding']['display']\n",
        "                elif ext['url'] == 'http://hl7.org/fhir/us/core/StructureDefinition/us-core-ethnicity':\n",
        "                    patient_data['ethnicity'] = ext['extension'][0]['valueCoding']['display']\n",
        "            patient_data['address'] = patient['address'][0]['city'] if 'address' in patient else None\n",
        "\n",
        "        elif resource_type == \"Condition\":\n",
        "            condition = resource\n",
        "            conditions.append({\n",
        "                'condition': condition['code']['coding'][0]['display'],\n",
        "                'clinicalStatus': condition.get('clinicalStatus', {}).get('coding', [{}])[0].get('code', None),\n",
        "                'verificationStatus': condition.get('verificationStatus', {}).get('coding', [{}])[0].get('code', None),\n",
        "                'onsetDateTime': condition.get('onsetDateTime', None)\n",
        "            })\n",
        "\n",
        "        elif resource_type == \"CarePlan\":\n",
        "            care_plan = resource\n",
        "            care_plans.append({\n",
        "                'plan': care_plan['activity'][0]['detail']['code']['coding'][0]['display'] if 'activity' in care_plan else None,\n",
        "                'status': care_plan.get('status', None),\n",
        "                'start': care_plan.get('period', {}).get('start', None)\n",
        "            })\n",
        "\n",
        "        elif resource_type == \"Encounter\":\n",
        "            encounter = resource\n",
        "            encounters.append({\n",
        "                'type': encounter['type'][0]['coding'][0]['display'] if 'type' in encounter else None,\n",
        "                'date': encounter.get('period', {}).get('start', None)\n",
        "            })\n",
        "\n",
        "        elif resource_type == \"DiagnosticReport\":\n",
        "            diagnostic_report = resource\n",
        "            diagnostic_reports.append({\n",
        "                'report': diagnostic_report['code']['coding'][0]['display'] if 'code' in diagnostic_report else None,\n",
        "                'effectiveDateTime': diagnostic_report.get('effectiveDateTime', None)\n",
        "            })\n",
        "\n",
        "        elif resource_type == \"Observation\":\n",
        "            observation = resource\n",
        "            observations.append({\n",
        "                'observation': observation['code']['coding'][0]['display'] if 'code' in observation else None,\n",
        "                'value': observation.get('valueQuantity', {}).get('value', None),\n",
        "                'unit': observation.get('valueQuantity', {}).get('unit', None),\n",
        "                'effectiveDateTime': observation.get('effectiveDateTime', None)\n",
        "            })\n",
        "\n",
        "        elif resource_type == \"Procedure\":\n",
        "            procedure = resource\n",
        "            procedures.append({\n",
        "                'procedure': procedure['code']['coding'][0]['display'] if 'code' in procedure else None,\n",
        "                'status': procedure.get('status', None),\n",
        "                'performedDateTime': procedure.get('performedDateTime', None)\n",
        "            })\n",
        "\n",
        "    return {\n",
        "        'patient_data': patient_data,\n",
        "        'conditions': conditions,\n",
        "        'care_plans': care_plans,\n",
        "        'encounters': encounters,\n",
        "        'diagnostic_reports': diagnostic_reports,\n",
        "        'observations': observations,\n",
        "        'procedures': procedures\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ubI2hNEPU-kU",
        "outputId": "8026545e-755b-43c7-802c-8d1560531149"
      },
      "outputs": [],
      "source": [
        "# Initialize vector_store as None\n",
        "vector_store = None\n",
        "\n",
        "def batch_data(data_list, batch_size):\n",
        "    \"\"\"Yield successive batches from data_list.\"\"\"\n",
        "    for i in range(0, len(data_list), batch_size):\n",
        "        yield data_list[i:i + batch_size]\n",
        "\n",
        "# Adjust the batch size as needed\n",
        "batch_size = 1\n",
        "\n",
        "# Process batches of trial data\n",
        "for i, batch in enumerate(batch_data(all_trials, batch_size)):\n",
        "    texts = []\n",
        "    metadatas = []\n",
        "    for trial in batch:\n",
        "        # Extract required fields from the trial data\n",
        "        description = trial.get('descriptionModule', {}).get('briefSummary', '')\n",
        "        location = trial.get('locationModule', {})\n",
        "        eligibility = trial.get('eligibilityModule', {})\n",
        "        nct_id = trial.get('identificationModule', {}).get('nctId', '')\n",
        "\n",
        "        # Combine description and eligibility criteria\n",
        "        combined_text = f\"NCTId:\\n{nct_id}\\nDescription:\\n{description}\\nEligibility Criteria:\\n{eligibility}\"\n",
        "\n",
        "        # Append the text and metadata\n",
        "        texts.append(combined_text)\n",
        "        metadatas.append({\n",
        "            'nctId': nct_id,\n",
        "            'eligibility': eligibility,\n",
        "            'location': location,\n",
        "        })\n",
        "\n",
        "    # If it's the first batch, initialize the FAISS vector store\n",
        "    if i == 0:\n",
        "        # Create the vector store from the texts and embeddings\n",
        "        vector_store = FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n",
        "    else:\n",
        "        # Add the new texts and metadata to the existing vector store\n",
        "        vector_store.add_texts(texts, metadatas=metadatas)\n",
        "\n",
        "# Optional: Save the FAISS vector store to disk for future use\n",
        "vector_store.save_local(\"faiss_store\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rkhWjs0mWRxf"
      },
      "outputs": [],
      "source": [
        "vector_store = FAISS.load_local(\"faiss_store\",embeddings,allow_dangerous_deserialization=True)\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "# k = 10  # Number of top documents to retrieve (increase this for more results)\n",
        "# results = retriever.get_relevant_documents(patient_info, k=k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KlG2WALi8-ve"
      },
      "outputs": [],
      "source": [
        "# Create a custom prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=\"\"\"\n",
        "You are an assistant that helps find clinical trials for patients.\n",
        "\n",
        "Given the following patient information and context, provide a list of all the clinical trials that the patient is eligible for, in the following format:\n",
        "\n",
        "NCT ID: [nctId]\n",
        "Brief Summary: [descriptionModule]\n",
        "Eligibility Criteria: [eligibilityModule]\n",
        "\n",
        "Patient Information: {question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mmAcvdhBWTQb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hq/f1b__lr163q9r1ljj554kc400000gn/T/ipykernel_4259/260244871.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n"
          ]
        }
      ],
      "source": [
        "# Initialize your language model\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Create a RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    # chain_type=\"stuff\"  # 'stuff' is suitable for simple concatenation\n",
        "    chain_type_kwargs={\"prompt\": prompt_template}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5ggha1BDWalz"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hq/f1b__lr163q9r1ljj554kc400000gn/T/ipykernel_4259/208526474.py:11: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
            "  agent = initialize_agent(\n"
          ]
        }
      ],
      "source": [
        "# Define the tool that uses the retriever\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Clinical Trial Retriever\",\n",
        "        func=lambda q: qa_chain.run(q),\n",
        "        description=\"Use this tool to fetch relevant clinical trials based on patient information.\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Initialize the agent with the new tool\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YJKcVe5HWfmG"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/hq/f1b__lr163q9r1ljj554kc400000gn/T/ipykernel_4259/4219724655.py:20: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = agent.run(query)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mTo find relevant clinical trials for Moen819, I should use the Clinical Trial Retriever tool, focusing on her active conditions: obesity and malignant neoplasm of the breast. These conditions are the most pertinent for identifying suitable clinical trials.\n",
            "\n",
            "Action: Clinical Trial Retriever\n",
            "Action Input: \"Female, born 1958, White, obesity, malignant neoplasm of breast, Quincy\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mBased on the provided patient information and context, the patient is eligible for the following clinical trial:\n",
            "\n",
            "NCT ID: NCT04365569  \n",
            "Brief Summary: More than 65% of breast cancer survivors are overweight and less than one-third participate in recommended levels of physical exercise. Obese breast cancer survivors have been found to have greater than a two-fold increase in mortality compared to women with normal body mass index (BMI). The current standard for weight loss interventions involves in-person counseling. However, this incurs costs related to travel for counseling sessions, potentially limiting program participation, compliance and sustainability. This is a pilot study of an individualized in-person and telephone-based nutrition and exercise counseling program.  \n",
            "Eligibility Criteria: \n",
            "- Inclusion Criteria:\n",
            "  - Breast cancer diagnosis (stage 0-III)\n",
            "  - Body mass index of 25mg/k2 or greater\n",
            "  - Actively being followed by medical oncologist, radiation oncologist, and/or breast surgeon at Maroone Cancer Center\n",
            "  - Able and willing to participate in nutrition counseling at Maroone Cancer Center\n",
            "  - Able (cleared by participant's primary oncologist) and willing to perform cardiopulmonary exercise testing\n",
            "  - Participants must have the ability to understand and the willingness to sign a written informed consent document\n",
            "  - Performance status 0 or 1 as per ECOG scale\n",
            "- Exclusion Criteria:\n",
            "  - Body mass index below 25kg/m2\n",
            "  - No prior history of breast cancer\n",
            "  - History of metastatic disease\n",
            "  - Not being followed by medical oncologist, radiation oncologist, and/or breast surgeon at Maroone Cancer Center\n",
            "  - Unable or unwilling to participate in nutrition counseling at Maroone Cancer Center\n",
            "  - Participants with uncontrolled intercurrent illness including, but not limited to ongoing or active infection, symptomatic congestive heart failure, unstable angina pectoris, cardiac arrhythmia, or psychiatric illness/social situations that would limit compliance with study requirements.\n",
            "  - Participants actively undergoing chemotherapy, immunotherapy or radiation treatment. However, participants currently taking hormonal therapy, such as selective estrogen receptor modulators (SERMS), or aromatase inhibitors, may be included in the study.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "\n",
            "Final Answer: Moen819 is eligible for the clinical trial NCT04365569, which is a pilot study of an individualized in-person and telephone-based nutrition and exercise counseling program for breast cancer survivors with a BMI of 25 or greater. This trial is suitable given her active conditions of obesity and malignant neoplasm of the breast.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Moen819 is eligible for the clinical trial NCT04365569, which is a pilot study of an individualized in-person and telephone-based nutrition and exercise counseling program for breast cancer survivors with a BMI of 25 or greater. This trial is suitable given her active conditions of obesity and malignant neoplasm of the breast.\n"
          ]
        }
      ],
      "source": [
        "# Function to interact with OpenAI API\n",
        "def generate_patient_data_response(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant tasked with reading patient data and outputting only the translated patient data, without including any additional information or explanations. Please structure the output in a clean and organized format.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "extracted_data = extract_patient_data(\"/Users/vijaykirandegala/Downloads/FHIR_STU4_Filtering/Sample_FHIR_Data/STU1/female/Magdalen131_Moen819_e209d094-31e4-4fc0-a314-0a2b2c6feaef.json\")\n",
        "\n",
        "prompt = f\"\"\"Patient data: {extracted_data}. Write a detailed description of the patientâ€™s clinical data to match them to relevant clinical trials. The final paragraph should be well-organized, coherent, and written in a narrative style to help an LLM efficiently retrieve relevant clinical trials through a RAG system.\n",
        "\"\"\"\n",
        "readble_patient_data = generate_patient_data_response(prompt)\n",
        "query = f\"\"\"{readble_patient_data}\"\"\"\n",
        "\n",
        "# Get the response from the agent\n",
        "response = agent.run(query)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVIGqosEUpQw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUTgtmkbU0Hk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVepoJIaWjg5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
